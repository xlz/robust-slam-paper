\section{Introduction}
Simultaneous localization and mapping (SLAM) is the central problem of autonomous robot navigation, and it also relates to 3-D reconstruction and augmented reality. Pose graph based SLAM approaches formulate it into an inference problem on a factor graph, where variable nodes are (unobserved) locations/poses of the robot and landmarks, and factor nodes are (observed) spatial constraints (usually Gaussians) between variable nodes. The goal of the inference problem is to obtain the maximum likelihood estimate of the joint probability, which will be the geometric estimates of robot trajectory and the map.


Problems arise when factors generated from faulty sensor data inconsistently link unrelated variable nodes, the estimated graph will be distorted. There are robust methods to deal with this, such as max-mixture\cite{mm} which represents factors not as a single spatial Gaussian distribution, but as a mixture of Gaussians, which can handle occasional outliers efficiently. There are also mature frameworks to efficiently optimize such estimation numerically\cite{isam}.

Such methods mainly considers perceptual aliasing errors stemmed from wrong loop closures, and they assume landmarks to be immovable in static environments. Unfortunately such assumptions do not hold for an important application of robot navigation in social environments, where there will be people moving around, and objects moving around. If a whole block of presumed ``landmarks'' change their locations, max-mixture will not be able to handle the systemic errors. As far as we know, the state of art of SLAM still deals with this problem by using external filtering to avoid moving objects as a whole, a method proposed by Thrun for self-driving cars 10 years ago.

We plan to devise new graph representations and algorithms to deal with this kind of data within the factor graph framework. The baseline will be the max-mixture method. There are plenty of existing implementations and datasets to try on.
